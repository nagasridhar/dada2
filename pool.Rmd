---
title: "Pooling samples"
---

The `dada` function implements the high-resolution sample-inference at the core of the dada2 package. Because `dada` resolves amplicon sequence variants (ASVs) exactly, [it is possible to analyze samples separately before combining them together in a final sequence table](https://www.nature.com/articles/ismej2017119). However, the `dada` function also allows samples to be pooled together sample inference. Here we demonstrate that functionality, and discuss the pros and cons of pooling.

-----------------------

# Getting ready

Load the necessary libraries:
```{r libraries, message=FALSE, warning=FALSE}
library(dada2); packageVersion("dada2")
```

We'll be working with the same data used in [the tutorial](tutorial.html), so grab that data if you don't have it already and then set your working directory to its location:

```{r path}
path <- "~/MiSeq_SOP" # CHANGE ME to the directory containing the fastq files after unzipping.
fnFs <- list.files(path, pattern="_R1_001.fastq$", full.names=TRUE)
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```

We'll trim and filter just the forward reads for simplicity:
```{r filter}
filtFs <- file.path(path, "filtered", paste0(sample.names, "_filtered.fq.gz"))
names(filtFs) <- sample.names
filterAndTrim(fnFs, filtFs, maxEE=2, truncLen=240, multithread=TRUE)
```

And we'll learn the error rates from these samples:
```{r learn}
err <- learnErrors(filtFs, multi=TRUE)
```

# Pooling for sample inference

De novo OTU methods must pool samples before processing them, as without pooling the labels between samples are not consistent and cannot be compared, i.e. OTU1 in sample 1 and OTU1 sample 2 won't be the same. DADA2 resolves amplicon sequence variants exactly, and [because exact DNA sequences are consistent labels, samples can be processed independently by DADA2 and then combined](https://www.nature.com/articles/ismej2017119), and this is the default behavior.

Independent sample processing has two major advantages: Computation time is linear in the number of samples, and memory requirements are flat with the number of samples. However, pooling allows information to be shared across samples, which makes it easier to resolve rare variants that were present as singletons or doubletone in one sample but were present many times across samples. Pooled sample inference is supported by calling `dada(..., pool=TRUE)`. **See also [the pseudo-pooling approach](pseudo.html#pseudo-pooling) introduced in version 1.8 that approximates full pooling in linear time.**

Let's start by processing our samples using the default sample-by-sample inference:
```{r dada-seperate}
system.time(dd.sep <- dada(filtFs, err=err))
```

Now we pool the samples for sample inference:
```{r dada-pool}
system.time(dd.pool <- dada(filtFs, err=err, pool=TRUE))
```

The pooled sample inference took longer, about twice as long in this case, but the delta between independent and pooled processing grows as study size increases. In practice, pooled processing can be used for Miseq scale data (especially if taking advantage of multithreading) but sample-by-sample processing [remains computationally tractable out to any study size](bigdata.html) (eg. 20 Hiseq runs).

We'll also take a quick look at the differences in output:
```{r make-table}
st <- makeSequenceTable(dd.sep)
st.sep <- removeBimeraDenovo(st, multithread=TRUE)

st <- makeSequenceTable(dd.pool)
st.pool <- removeBimeraDenovo(st, multithread=TRUE)

dim(st.sep); dim(st.pool)
```

As expected, pooling detected a few more amplicon sequence variants (ASVs) due to an increased power to detect rare variants.

```{r compare}
sq.sep <- getSequences(st.sep)
sq.pool <- getSequences(st.pool)
sum(!sq.sep %in% sq.pool);sum(sq.sep %in% sq.pool); sum(!sq.pool %in% sq.sep)

sum(st.sep[,!sq.sep %in% sq.pool])
sum(st.sep[,sq.sep %in% sq.pool])
sum(st.pool[,sq.pool %in% sq.sep])
sum(st.pool[,!sq.pool %in% sq.sep])
```

The large majority of ASVs, and the vast majority of reads (>99%) are commonly assigned between these methods. Either method provides an accurate reconstruction of your sampled communities.

